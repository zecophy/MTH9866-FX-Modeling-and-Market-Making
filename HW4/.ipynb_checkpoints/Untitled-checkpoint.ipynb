{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4 (Options Markets) Assignment\n",
    "\n",
    "### Chenyu Zhao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (4 marks)\n",
    "\n",
    "The current time is Wednesday at 1pm and you see the overnight implied volatility (for 10am expiration on Thursday) trading at 9%. The FX markets are open for trading every hour between now and tomorrow at 10am.\n",
    "\n",
    "The Federal Reserve Chairwoman is speaking about the economy from 2-3pm, and that event adds an extra 0.5 trading days worth of variance on top of the usual variance for that time period.\n",
    "\n",
    "What should the overnight implied volatility be at 3pm, all else being equal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "The total trading hour is 21 hours. After adding the extra time from event, the total hour is 33 hours. \n",
    "\n",
    "After the event, the calendar time pass 2 hours and the extra hours gone, so the total hours is 19.\n",
    "\n",
    "Because the total variance $\\sigma^2 T$ is same, so the overnight implied vol is \n",
    "\n",
    "$$\n",
    "\\sigma_{\\text{3pm}} = \\sqrt{\\frac{19}{33}} \\sigma = 6.83\\%\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (3 marks)\n",
    "\n",
    "In stochastic volatility models, why is there a smile? Describe the genesis of the smile in terms of vega gamma.\n",
    "\n",
    "Similarly, describe why stochastic volatility models generate a skew, in terms of vega dspot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Smile comes from vol of vol, which can be regarded as vega gamma $\\frac{\\partial^2}{\\partial \\sigma^2}$\n",
    "\n",
    "1. Buy an option with strike such that vega gamma is large. Now you long both vega and vega gamma.\n",
    "\n",
    "2. Vega hedge with an appropriate amount of ATM option. Since ATM option has zero vega gamma, so still long vega gamma.\n",
    "\n",
    "3. Now whichever way vol moves you make money! Because the first derivative is 0 and second derivative is positive. So you portfolio now is at the local minimum point, with respect to vol. When vol moves, the value of your portfolio rises.\n",
    "\n",
    "4. More volatility of volatility, bigger the smile\n",
    "\n",
    "5. So traders tend to buy option with big or small strike and sell ATM option, make option with big or small strike more valuable, thus create vol smile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skew comes from vega dspot $\\frac{\\partial^2}{\\partial \\sigma \\partial S}$, or the cross gamma between spot and volatility (“vanna”).\n",
    "\n",
    "1. Buy a high strike option, you have Positive vega dspot, positive vega\n",
    "\n",
    "2. Sell enough ATM to vega hedge. Because ATM option has zero vega dspot, your portfolio still long vega dspot\n",
    "\n",
    "3. if we assume positive spot/vol correlation, then your portfolio at local minimum point on $\\sigma-s$ plain. You can always make money when vol move.\n",
    "\n",
    "4. When buy a low strike option, and hedge with ATM option, the sign flips\n",
    "5. So traders tend to buy option with big strike and sell option with low strike, thus create vol skew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (2 marks)\n",
    "\n",
    "Why do most FX shops use a “sticky delta” volatility market model when defining delta for hedging purposes, even though that might not give the most accurate estimate of how implied volatilities, and hence portfolio prices, change when spot moves?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Because of market convention. In FX market, traders trade vol by delta. For example, 25 delta butterfly, 10 delta reversal. Thus when trade, trades would like to keep vol by delta same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (4 marks)\n",
    "\n",
    "Consider an ATM EURGBP option with 0.5y to expiration. Assume the EURGBP ATM volatility is 3.5%, the EURUSD ATM volatility is 8.5%, and the GBPUSD ATM volatility is 7.5%. What is the implied correlation between EURUSD and GBPUSD spots?\n",
    "\n",
    "EURUSD spot is 1.25 and GBPUSD spot is 1.56; assume zero interest rates.\n",
    "\n",
    "Use the Black-Scholes vega formula to calculate the vegas of all three options and determine the notionals of EURUSD and GBPUSD options needed to hedge the vegas of 1 EUR notional of the EURGBP option, assuming correlation stays constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "cross vol is corrected by\n",
    "\n",
    "$$\n",
    "\\sigma_x = \\sqrt{\\sigma_1^2+\\sigma_2^2-2\\rho\\sigma_1\\sigma_2}\n",
    "$$\n",
    "\n",
    "$\\sigma_x=3.5\\%$, $\\sigma_1=8.5\\%$ and $\\sigma_2=7.5\\%$, thus we have $\\rho=91.2\\%$, which is tme implied correlation.\n",
    "\n",
    "For ATM vega under Black-Scholes framework, $K=Fe^{\\frac12 \\sigma^2 T}$, $vega = F\\sqrt{\\frac{T}{2\\pi}}e^{-\\frac{(R-Q)^2T}{2\\sigma^2}-QT}$. Because $R=Q=0$, therefore\n",
    "\n",
    "$$\n",
    "vega = F\\sqrt{\\frac{T}{2\\pi}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "vaga_1 = 0.3526\n",
    "$$\n",
    "\n",
    "$$\n",
    "vaga_2= 0.4401\n",
    "$$\n",
    "\n",
    "$$\n",
    "vaga_x = 0.3521\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct a portfolio,long 1 unit EURGBP option in EUR notion and short $N_1$ EURUSD and $N_2$ GBPUSD. Now we write our portfolio's value in USD .\n",
    "\n",
    "$$\n",
    "\\Pi = 1.56V_x -N_1V_1-N_2V_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\Pi}{\\partial \\sigma_1} = 1.56\\frac{\\partial V_x}{\\partial \\sigma_x}\\frac{\\partial \\sigma_x}{\\partial \\sigma_1}-N_1\\frac{\\partial V_1}{\\partial \\sigma_1}=1.56 vega_x\\frac{\\sigma_1-\\rho\\sigma_2}{\\sigma_x}-N_1 vega_1 =0\n",
    "$$\n",
    "\n",
    "Thus $N_1 = 0.7369$\n",
    "\n",
    "Take derivative to $\\sigma_2$, we can get similar expression. \n",
    "\n",
    "thus $N_2 = -0.089$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (10 marks)\n",
    "\n",
    "In this question you will look at implied correlations and see how much moves in implied correlation contribute to moves in cross volatility, versus moves in the underlying USD-pair volatilities.\n",
    "\n",
    "Consider the AUDJPY market, where the underlying USD pairs are AUDUSD and USDJPY. \n",
    "\n",
    "For a given expiration tenor, one can calculate the market-implied correlation between moves in AUDUSD spot and USDJPY spot through the implied volatilities for the three pairs.\n",
    "\n",
    "First step: write code to calculate these correlations in a window from 1Jan2007 to 31May2013. I have posted a spreadsheet with the ATM implied volatilities for AUDUSD, USDJPY, and AUDJPY for various expiration tenors on the class forum.\n",
    "\n",
    "You should write a function that takes in the names of the three pairs (as strings like ‘AUDJPY’, ‘AUDUSD’, and ‘USDJPY’), a string tenor (like ‘3m’), a flag to define whether the cross spot is the product or the ratio of the two USD spots (which affects the sign of the correlation), and the start and end dates of the historical window.\n",
    "\n",
    "It should start by loading the data for the ATM implied volatility for the three tenors from the spreadsheet into pandas DataFrames and then calculate a pandas DataFrame of implied correlations.\n",
    "\n",
    "The next step: use the correlation from date i, along with the implied volatilities for the USD pairs on date i+1, to predict the cross volatility on date i+1. Do this with the pandas DataFrames you have already created.\n",
    "\n",
    "Finally, construct two DataFrames: one holding day-to-day changes in the cross ATM volatility, and one holding differences between the predicted cross volatility (assuming the implied correlation from the day before) and the true cross volatility.\n",
    "\n",
    "The function should print out statistics on both those series.\n",
    "\n",
    "Run this for the following list of tenors: 1w, 1m, 6m, and 1y. Comment on any differences across tenors, and whether this seems like a good hedging strategy for hedging AUDJPY volatility. Make sure to refer to statistics of the two series, both standard deviations as well as maximum and minimum deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "day-to-day changes in the cross ATM volatility stands for hedged change. The hedge method is to assume correlation stay same from previous day then use the model to predict next day's vol.\n",
    "\n",
    "\n",
    "differences between the predicted cross volatility (assuming the implied correlation from the day before) and the true cross volatility stands for unhedged change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T19:40:58.410778Z",
     "start_time": "2019-09-26T19:40:58.174539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AUDUSD 1w</th>\n",
       "      <th>AUDUSD 1m</th>\n",
       "      <th>AUDUSD 6m</th>\n",
       "      <th>AUDUSD 1y</th>\n",
       "      <th>USDJPY 1w</th>\n",
       "      <th>USDJPY 1m</th>\n",
       "      <th>USDJPY 6m</th>\n",
       "      <th>USDJPY 1y</th>\n",
       "      <th>AUDJPY 1w</th>\n",
       "      <th>AUDJPY 1m</th>\n",
       "      <th>AUDJPY 6m</th>\n",
       "      <th>AUDJPY 1y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>7.1500</td>\n",
       "      <td>7.1750</td>\n",
       "      <td>7.3250</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>6.5500</td>\n",
       "      <td>6.75000</td>\n",
       "      <td>6.90000</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7.2750</td>\n",
       "      <td>7.3250</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>6.8000</td>\n",
       "      <td>6.3000</td>\n",
       "      <td>6.62500</td>\n",
       "      <td>6.85000</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7.4100</td>\n",
       "      <td>7.4300</td>\n",
       "      <td>7.0018</td>\n",
       "      <td>6.7006</td>\n",
       "      <td>6.85045</td>\n",
       "      <td>6.92543</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>7.7522</td>\n",
       "      <td>7.3007</td>\n",
       "      <td>7.4006</td>\n",
       "      <td>7.4506</td>\n",
       "      <td>6.8000</td>\n",
       "      <td>6.9500</td>\n",
       "      <td>6.90000</td>\n",
       "      <td>6.92000</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>7.3000</td>\n",
       "      <td>7.3000</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>6.7500</td>\n",
       "      <td>6.7250</td>\n",
       "      <td>6.85000</td>\n",
       "      <td>6.95000</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AUDUSD 1w  AUDUSD 1m  AUDUSD 6m  AUDUSD 1y  USDJPY 1w  \\\n",
       "0 2007-01-02     7.5000     7.1500     7.1750     7.3250     7.0000   \n",
       "1 2007-01-03     7.9250     7.2750     7.3250     7.4000     6.8000   \n",
       "2 2007-01-04     7.7500     7.2500     7.4100     7.4300     7.0018   \n",
       "3 2007-01-05     7.7522     7.3007     7.4006     7.4506     6.8000   \n",
       "4 2007-01-08     7.0500     7.3000     7.3000     7.4000     6.7500   \n",
       "\n",
       "   USDJPY 1m  USDJPY 6m  USDJPY 1y  AUDJPY 1w  AUDJPY 1m  AUDJPY 6m  AUDJPY 1y  \n",
       "0     6.5500    6.75000    6.90000       6.75        6.4       7.15       7.55  \n",
       "1     6.3000    6.62500    6.85000       6.75        6.4       7.15       7.55  \n",
       "2     6.7006    6.85045    6.92543       6.75        6.4       7.15       7.55  \n",
       "3     6.9500    6.90000    6.92000       7.50        7.5       7.30       7.40  \n",
       "4     6.7250    6.85000    6.95000       7.50        7.5       7.30       7.40  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_excel(\"fx_vol_data.xlsx\", index=\"Date\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T19:45:05.064410Z",
     "start_time": "2019-09-26T19:45:05.055585Z"
    }
   },
   "outputs": [],
   "source": [
    "def analyse(pairx, pair1, pair2, tenor):\n",
    "    colx = pairx + ' ' + tenor\n",
    "    col1 = pair1 + ' ' + tenor\n",
    "    col2 = pair2 + ' ' + tenor\n",
    "\n",
    "    # implied correlation \n",
    "    impCorr = (data[col1]**2 + data[col2]**2 - data[colx]**2) / (2.0 * data[col1] * data[col2])\n",
    "\n",
    "    # predict corr for next day\n",
    "    preVol = np.sqrt(data[col1]**2 + data[col2]**2 - 2 * impCorr.shift(1) * data[col1] * data[col2])\n",
    "    \n",
    "    #  differences between the predicted cross volatility and true\n",
    "    diff = preVol - data[colx]\n",
    "    \n",
    "    # day-to-day changes\n",
    "    dailyChange = data[colx].shift(1) - data[colx]\n",
    "\n",
    "    return (diff.std(), diff.max(), diff.min(), dailyChange.std(), dailyChange.max(), dailyChange.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T19:45:05.560477Z",
     "start_time": "2019-09-26T19:45:05.516821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1w\n",
      "    hedged std:  1.1860375166916477\n",
      "  unhedged std:  1.7954802329602413\n",
      "    hedged max:  14.951414531317791\n",
      "  unhedged max:  15.88000000000001\n",
      "    hedged min:  -13.923782223730102\n",
      "  unhedged min:  -18.805\n",
      "\n",
      "\n",
      "1m\n",
      "    hedged std:  0.7424009483363391\n",
      "  unhedged std:  1.0965227442381238\n",
      "    hedged max:  7.8661789705795115\n",
      "  unhedged max:  8.627499999999998\n",
      "    hedged min:  -7.311626492498494\n",
      "  unhedged min:  -12.5475\n",
      "\n",
      "\n",
      "6m\n",
      "    hedged std:  0.38322620425349\n",
      "  unhedged std:  0.5750494585473307\n",
      "    hedged max:  5.884164426715095\n",
      "  unhedged max:  3.7225\n",
      "    hedged min:  -3.4158506536508764\n",
      "  unhedged min:  -4.922499999999999\n",
      "\n",
      "\n",
      "1y\n",
      "    hedged std:  0.31596331415981366\n",
      "  unhedged std:  0.43140724936073804\n",
      "    hedged max:  4.6054202940061835\n",
      "  unhedged max:  2.482499999999998\n",
      "    hedged min:  -3.265281784524058\n",
      "  unhedged min:  -3.717500000000001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tenors = ['1w', '1m', '6m', '1y']\n",
    "\n",
    "for tenor in tenors:\n",
    "    print(tenor)\n",
    "    std1,max1,min1,std2,max2,min2 = analyse('AUDJPY','AUDUSD','USDJPY',tenor)\n",
    "    print(\"    hedged std: \",std1)\n",
    "    print(\"  unhedged std: \",std2)\n",
    "    print(\"    hedged max: \",max1)\n",
    "    print(\"  unhedged max: \",max2)\n",
    "    print(\"    hedged min: \",min1)\n",
    "    print(\"  unhedged min: \",min2)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions\n",
    "\n",
    "1. hedge for short tenor is better than long tenor, as max, min and std are all smaller than long tenor's\n",
    "\n",
    "2. for long tenor like 6m or 1y, std is reduced but max and min increase.\n",
    "\n",
    "3. assuming day-to-day vol not change is ok, though not work very well, but reduce risk somehow. Reduce about 25% - 33% std."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
